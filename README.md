# ğŸ” Multi-Document RAG Search Engine

**(Documents + Real-Time Web | Groq LLM | FAISS | Tavily | Streamlit)**

---
## ğŸ“Œ Project Overview

This project implements a **Hybrid Retrieval-Augmented Generation (RAG) Search Engine** that intelligently answers user queries by combining:

* **User-uploaded documents (PDFs)**
* **Semantic vector search using FAISS**
* **Real-time web search using Tavily**
* **Large Language Model inference using Groq (LLaMA-3)**

Unlike traditional RAG systems that rely only on static documents, this system dynamically decides **when to use document knowledge, live web data, or both**, and returns **source-grounded answers with clear citations**.

This mirrors real-world enterprise AI copilots and research assistants.

---

## ğŸ¯ Key Objectives

* Build a **multi-document semantic search engine**
* Implement **Hybrid RAG (Document + Web)**
* Enable **real-time knowledge access**
* Ensure **transparent, citation-aware answers**
* Deliver a clean, interactive **Streamlit chatbot UI**

---

## ğŸ§  System Architecture

```
User Query
   â”‚
   â”œâ”€â”€ Query Router (Document / Web / Hybrid)
   â”‚
   â”œâ”€â”€ FAISS Vector Search (Uploaded PDFs)
   â”‚
   â”œâ”€â”€ Tavily Real-Time Web Search
   â”‚
   â”œâ”€â”€ Context Assembly & Source Tagging
   â”‚
   â””â”€â”€ Groq LLM â†’ Answer with Citations
```

---

## ğŸ§° Tech Stack

| Component            | Technology                        |
| -------------------- | --------------------------------- |
| Programming Language | Python                            |
| LLM                  | Groq (LLaMA-3)                    |
| LLM Orchestration    | LangChain                         |
| Embeddings           | HuggingFace Sentence Transformers |
| Vector Database      | FAISS                             |
| Web Search           | Tavily Search API                 |
| Frontend             | Streamlit                         |

---

## ğŸ“ Project Structure

```
hybrid_rag/
â”‚
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ config.py                  # API keys & configs
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ loaders.py             # PDF loaders
â”‚   â”œâ”€â”€ cleaner.py             # Text normalization
â”‚   â”œâ”€â”€ chunker.py             # Chunking logic
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â”œâ”€â”€ faiss_index.py         # FAISS index creation & loading
â”‚
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ semantic_search.py     # Vector similarity search
â”‚   â”œâ”€â”€ web_search.py          # Tavily web retrieval
â”‚   â”œâ”€â”€ router.py              # Query classification
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ context_builder.py     # Context construction
â”‚   â”œâ”€â”€ qa_chain.py            # Groq RAG pipeline
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ schemas.py             # Unified data models
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ helpers.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ Workflow

1. **User uploads PDFs** via Streamlit UI
2. Documents are:

   * Cleaned
   * Chunked
   * Embedded
   * Indexed in FAISS
3. User submits a query
4. Query is classified as:

   * Document-based
   * Web-based
   * Hybrid
5. Relevant context is retrieved from:

   * FAISS
   * Tavily Web Search
6. Groq LLM generates a **grounded answer with citations**
7. Sources are transparently displayed to the user

---

## ğŸ§ª Example Queries

* *â€œExplain attention mechanism in transformersâ€* â†’ ğŸ“„ Document Search
* *â€œLatest advancements in RAG systemsâ€* â†’ ğŸŒ Web Search
* *â€œHow does RAG compare with current LLM tools?â€* â†’ ğŸ”€ Hybrid Search

---

## ğŸ“Š Key Features

* âœ… Multi-document semantic search
* âœ… Real-time web integration
* âœ… Hybrid query routing
* âœ… Citation-aware answer generation
* âœ… Modular, production-ready codebase
* âœ… Clean Streamlit UI

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/hybrid-rag-search-engine.git
cd hybrid-rag-search-engine
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Environment Variables

Create a `.env` file:

```env
GROQ_API_KEY=your_groq_api_key
TAVILY_API_KEY=your_tavily_api_key
```

### 5ï¸âƒ£ Run Application

```bash
streamlit run app.py
```

---

## ğŸ“ˆ Evaluation Scenarios

* Static document-based knowledge retrieval
* Real-time factual queries
* Hybrid reasoning across documents and the web
* Citation clarity and source separation

---

## ğŸš€ Future Enhancements

* Conversational memory
* Advanced query classification using LLMs
* Re-ranking with cross-encoders
* Source confidence scoring
* Streaming responses
* User authentication & document management

---

## ğŸ“ Learning Outcomes

This project demonstrates:

* Hybrid RAG system design
* Enterprise-grade document retrieval
* Real-time web augmentation
* Explainable and trustworthy AI
* End-to-end LLM application development

---

## ğŸ‘¤ Author

**Akshat Mishra**
